{
   "GLOBAL": {
      "EXAMPLES": "Examples",
      "WORKFLOWS": "Workflows",
      "TEMPLATES": "Templates",
      "INPUTS": "Inputs",
      "INPUT": "Input",
      "OUTPUTS": "Outputs",
      "OUTPUT": "Output",
      "TRANSFORMATIONS": "Transformations",
      "TRANSFORMATION": "Transformation",
      "SETTINGS": "Settings",
      "BACKUPS": "Backups",
      "CROSSDATA": "Crossdata",
      "FOLDER": "Folder",
      "DRIVERS": "DRIVERS",
      "PLUGINS": "PLUGINS",
      "RAW DATA": "Raw data",
      "TRIGGERS": "Triggers",
      "TRIGGER": "Trigger",
      "CUBES": "Cubes",
      "CUBE": "Cube",
      "GREETINGS": "Hello World!",
      "RESOURCES": "Resources",
      "DISPLAY": "Display:",
      "DOCUMENTATION_LINK": "Stratio Product Documentation",
      "HELP_TITLE": "Help",
      "FILTER_PLACEHOLDER": "Filter by element...",
      "USER_PROFILE": {
         "TITLE": "PROFILE",
         "LOGOUT": "Log out"
      }
   },
   "DASHBOARD": {
      "HOME": {
         "MONITORING_TITLE": "Home",
         "SEARCH_PLACEHOLDER": "Search by group, workflow, status or tag",
         "WORKFLOWS": "workflows",
         "RUNNING": "running",
         "ALL_WORKFLOWS": "all workflows",
         "STARTING": "starting",
         "FAILED": "failed",
         "STOPPED": "stopped",
         "NOT_STARTED": "not started"
      },
      "CREATE_FIRST_WORFKOW": "Create your first workflow",
      "CREATE_FIRST_WORFKOW_DESCRIPTION": "You can choose inputs, transformations, analytical processes and results to extract information from your data in real time.",
      "STREAMING_TITLE": "Streaming workflow",
      "STREAMING_DESCRIPTION": "Process data from a live data source.(e.g: kafka)",
      "BATCH_TITLE": "Batch workflow",
      "BATCH_DESCRIPTION": "Process data from a static bounded data source (e.g: file).",
      "UPLOAD_JSON_LINK": "Upload from JSON file",
      "NEW_WORKFLOW": "New workflow",
      "DATABASE": "Database",
      "CHOOSE_METHOD": "Choose method:",
      "NEW_WORKFLOW_SCRATCH": "New workflow from scratch",
      "NEW_WORKFLOW_JSON": "New workflow from json file",
      "OR": "OR",
      "SET_CONFIGURATION": "Set configuration",
      "UPLOAD_JSON": "Upload JSON",
      "UPLOAD_JSON_FILE": "Upload JSON file",
      "UPLOAD_DRIVER": "Upload driver",
      "UPLOAD_PLUGIN": "Upload plugin",
      "JSON_TITLE": "Import from JSON",
      "COMPLETE_PATH": "Complete path",
      "CREATE_GROUP_TITLE": "New folder",
      "CANCEL": "Cancel",
      "CREATE": "Create",
      "SAVE": "Save",
      "ADD_ENVIRONMENT": "Add environment variable",
      "ENVIRONMENT": "Environment",
      "NAME_PLACEHOLDER": "Workflow name",
      "DESCRIPTION_PLACEHOLDER": "Workflow description",
      "WORKFLOW_NAME": "Name",
      "WORKFLOW_DESCRIPTION": "Description",
      "DELETE_WORKFLOW_TITLE": "Delete Workflow",
      "DELETE_WORKFLOW_MESSAGE": "Are you sure?",
      "DELETE_FOLDER_TITLE": "Delete Folder",
      "DELETE_VERSION_TITLE": "Delete Version",
      "DELETE_TITLE": "Delete",
      "MOVE_GROUP_TITLE": "Move to",
      "MESSAGE_DELETE_TITLE": "This action cannot be reversed.",
      "DUPLICATE_WORKFLOW": "Duplicate workflow",
      "RENAME_WORKFLOW_TITLE": "Rename workflow",
      "RENAME_FOLDER_TITLE": "Rename group",
      "RENAME_INPUT_PLACEHOLDER": "Current name",
      "RENAME_WORKFLOW_INPUT_LABEL": "Workflow name",
      "RENAME_GROUP_INPUT_LABEL": "Folder name",
      "WORKFLOW_INFO": "Select a workflow to view its details",
      "EXECUTION_INFO": "Select a execution to view its details",
      "NODE_INFO": "Select a node to view its details",
      "WORKFLOW_JSON": "Paste or upload json workflow definition",
      "JSON_INFO": "You must enter the new name and description before you can save the workflow, it will overwrite the fields of the json",
      "JSON_SAVE_ERROR": "Parse Error. Workflow definition must be in json format.",
      "STATUS_INFORMATION": "Status information",
      "LAST_ERROR": "Last error",
      "LAST_UPDATE": "Last update",
      "LAST_STATUS_UPDATE": "Last status update",
      "TAGS": "Tags",
      "COMPLETE_STATUS": "Advanced status",
      "NOTSTARTED": "Not started",
      "FAILED": "Failed",
      "LAUNCHED": "Launched",
      "STOPPED": "Stopped",
      "STOPPING": "Stopping",
      "FINISHED": "Finished",
      "STARTED": "Started",
      "RUNNING": "Running",
      "STARTING": "Starting",
      "KILLED": "Killed",
      "NOTDEFINED": "Not defined",
      "UPLOADED": "Uploaded",
      "CREATED": "Created",
      "DELETE_INPUT_TITLE": "Delete input",
      "DELETE_INPUT_MESSAGE": "This action cannot be reverted.",
      "DELETE_INPUT_MESSAGE_TITLE": "Are you sure?",
      "DELETE_OUTPUT_TITLE": "Delete output",
      "DELETE_OUTPUT_MESSAGE": "This action cannot be reverted.",
      "DELETE_OUTPUT_MESSAGE_TITLE": "Are you sure?",
      "DELETE_TRANSFORMATION_TITLE": "Delete transformation",
      "DELETE_TRANSFORMATION_MESSAGE": "This action cannot be reverted.",
      "DELETE_TRANSFORMATION_MESSAGE_TITLE": "Are you sure?",
      "NEW_INPUT": "New input",
      "NEW_OUTPUT": "New output",
      "NEW_TRANSFORMATION": "New transformation",
      "CREATE_INPUT": "Create input",
      "CREATE_OUTPUT": "Create output",
      "CREATE_TRANSFORMATION": "Create transformation",
      "EDIT": "Edit",
      "EDIT_INPUT": "Edit input",
      "EDIT_OUTPUT": "Edit output",
      "EDIT_TRANSFORMATION": "Edit transformation",
      "DUPLICATE": "Duplicate",
      "DUPLICATE_TRANSFORMATION": "Duplicate transformation",
      "DUPLICATE_INPUT": "Duplicate input",
      "DUPLICATE_OUTPUT": "Duplicate output",
      "SAVE_INPUT": "Save input",
      "SAVE_OUTPUT": "Save output",
      "SAVE_TRANSFORMATION": "Save transformation",
      "EDIT_FRAGMENT": "Edit",
      "DUPLICATE_FRAGMENT": "Duplicate",
      "DELETE_FRAGMENT": "Delete",
      "TEMPLATE_NAME": "Name",
      "TEMPLATE_DESCRIPTION": "Description",
      "FRAGMENT_DUPLICATE_ERROR": "There was an error. The name of the fragment already exists!",
      "GENERATE_BACKUP": "Generate backup",
      "UPLOAD_BACKUP": "Upload backup",
      "DELETE": "Delete",
      "DOWNLOAD": "Download",
      "EXECUTE": "Execute",
      "EXECUTE_BACKUP_TITLE": "Execute backup",
      "DELETE_ALL_BACKUPS": "Delete all backups",
      "DELETE_ALL_BACKUPS_TITLE": "Delete all backups",
      "DELETE_ALL_BACKUPS_MESSAGE": "This action can not be reversed.",
      "DELETE_ALL_BACKUPS_MESSAGE_TITLE": "Are you sure?",
      "DELETE_BACKUP_TITLE": "Delete backup",
      "DELETE_BACKUP_MESSAGE": "This action can not be reversed.",
      "DELETE_BACKUP_MESSAGE_TITLE": "Are you sure?",
      "DELETE_METADATA": "Delete metadata",
      "DELETE_METADATA_TITLE": "Delete metadata",
      "DELETE_METADATA_MESSAGE": "This action can not be reversed.",
      "DELETE_METADATA_TITLE_MESSAGE": "Are you sure?",
      "DELETE_DRIVER_TITLE": "Delete driver",
      "DELETE_DRIVER_MESSAGE": "Are you sure?",
      "DELETE_PLUGIN_TITLE": "Delete plugin",
      "DELETE_PLUGIN_MESSAGE_TITLE": "Are you sure?",
      "DELETE_PLUGIN_MESSAGE": "This action can not be reversed.",
      "FILTER_TABLES": "Filter tables",
      "FILTER_ENVIRONMENT": "Search variable",
      "FILTER_LIST": "Search list",
      "FILTER_CONTEXT": "Search context",
      "SHOW_TEMPORARY": "Show temporary tables",
      "EXECUTE_QUERY": "Execute query",
      "EXECUTE_BACKUP_CONFIRMATION": "Are you sure?",
      "SQL_QUERY": "SQL query",
      "INPUT_TYPE": "Input type",
      "OUTPUT_TYPE": "Output type",
      "TRANSFORMATION_TYPE": "Transformation type",
      "CATALOG": "Catalog",
      "CATALOG_DESCRIPTION": "Retrieve Crossdata databases and tables catalog.",
      "QUERIES": "Queries",
      "QUERIES_DESCRIPTION": "Execute queries in Crossdata.",
      "CROSSDATA": "Crossdata",
      "EXECUTE_QUERY_OK": "Executed SQL: ({{rows}} rows returned)",
      "EXECUTE_QUERY_OK_NO_LIST": "Query completed succesfully.",
      "DELETE_VERSION": "The selected versions have been deleted",
      "DELETE_SINGLE_GROUP": "The folder has been deleted succesfully",
      "DELETE_SINGLE_VERSION": "The version has been deleted succesfully",
      "CREATE_GROUP": "The folder has been created succesfully",
      "RENAME_GROUP": "The folder has been renamed succesfully",
      "MOVE_GROUP": "The folder has been updated",
      "RENAME_WORKFLOW": "The workflow has been renamed",
      "MOVE_WORKFLOW": "The workflow has been moved",
      "DELETE_WORKFLOW": "The selected workflows have been removed",
      "RUN_NOW_BUTTON": "Ok, run now",
      "CONTEXT_CONFIG": "Your workflow will be launched in these contexts:",
      "ENVIRONMENT_CONTEXT": "Environment context",
      "GROUP_CONTEXT": "Group A context",
      "NO_DEFINITION_PARAMS": "These parameters has no definition. Please, type one:"
   },
   "ENVIRONMENT": {
      "SUBTITLE": "Upload an environment backup file",
      "DESCRIPTION": "Importing an environment could cause a potential loss of data.",
      "PARSE_ERROR": "Parse error. Environment must be a json file.",
      "DUPLICATED_VARIABLE": "Duplicated environment variable name",
      "CONFIRM": "Confirm",
      "CANCEL": "Cancel"
   },
   "SETTINGS": {
      "_UDF_NAME": "UDF class name",
      "_USER_UDFS_": "Register UDFs",
      "_USER_UDAFS_": "Register UDAFs",
      "_ERROR_WHEN_ERROR_": "Error handling policy",
      "_ERROR_WHEN_ROW_ERROR_": "Row error handling policy",
      "_ERROR_WHEN_FIELD_ERROR_": "Field error handling policy",
      "_ERROR_INPUT_ACTION_": "When an error occurs do",
      "_ERROR_TRANSFORMATION_ACTION_": "When an error occurs do",
      "_ERROR_TRANS_TO_OUTPUTS_": "Send input steps data to",
      "_OUTPUT_STEP_NAME_": "Output name",
      "_OMIT_ERRORS_": "Omit errors on send",
      "_ERROR_SAVE_ACTION_": "When an error occurs do",
      "_ERROR_SAVE_TO_OUTPUTS_": "When an error occurs, send data to",
      "_SEND_INPUT_DATA_": "If transformation fails, send inputs data",
      "_SEND_PREDECESSORS_DATA_": "If transformation fails, send predecessors data",
      "_ADD_REDIRECT_DATE_": "Add redirect date",
      "_REDIRECT_DATE_NAME_": "Redirect date column name",
      "_SEND_STEP_DATA_": "If output fails, send processed data",
      "_MESOS_CONSTRAINT_": "Mesos constraint",
      "_MESOS_CONSTRAINT_OPERATOR_": "Constraint operator",
      "_SPARK_MESOS_SECURITY_ENABLE_": "Mesos security",
      "_SPARK_DEFAULT_PARALLELISM_": "Default parallelism",
      "_SPARK_KRYO_": "Use Kryo Serialization",
      "_SPARK_SQL_CASE_SENSITIVE_": "Case sensitive in SQL",
      "_NAME_": "Name",
      "_DESCRIPTION_": "Description",
      "_EXECUTION_MODE_": "Execution Mode",
      "_TEMPORAL_TABLE_TRANSFORMATIONS_": "Transformations temporal table",
      "_MONITORING_LINK_": "Monitoring link",
      "_USER_PLUGINS_JARS_": "User plugins",
      "_JAR_PATH": "Jar file URI",
      "_SQL_SENTENCE_": "SQL sentence",
      "_INITIAL_SQL_SENTENCES_": "Pre-execution SQL queries",
      "_FINAL_SQL_SENTENCES_": "Post-execution SQL queries (batch only)",
      "_ENABLE_CHECKPOINT_": "Enable",
      "_AUTO_DELETE_CHECKPOINT_": "Auto-delete checkpoint",
      "_ADD_TIME_TO_CHECKPOINT_": "Add time to checkpoint path",
      "_CHECKPOINT_PATH_": "Checkpoint path",
      "_SPARK_STREAMING_WINDOW_": "Window",
      "_ADD_ALL_UPLOADED_PLUGINS_": "Add uploaded plugins",
      "_WHITE_SPACE_": " ",
      "_POLICY_REMEMBER_FIELD_": "Max query execution time",
      "_SPARK_MASTER_": "Master",
      "_SPARK_HOME_": "Home",
      "_SPARK_KILL_URL_": "Kill URL (dispatcher)",
      "_SPARK_USER_": "Spark User",
      "_SPARK_KERBEROS_ENABLE_": "Kerberos",
      "_SPARK_DATASTORE_TLS_ENABLE_": "TLS",
      "_SPARK_CONF_": "User properties",
      "_SPARK_STOP_GRACEFUL_TIMEOUT_": "Graceful timeout",
      "_SPARK_SERIALIZER_": "Serializer",
      "_SPARK_EXECUTOR_URI_": "Executor URI",
      "_SPARK_COARSE_": "Coarse",
      "_SPARK_PARQUET_BINARY_STRING_": "Parquet binary as string",
      "_SPARK_LOG_STAGES_PROGRESS_": "Show stages progress in logs",
      "_SPARK_HDFS_DISABLE_CACHE_": "Disable HDFS cache",
      "_SPARK_STOP_GRACEFULLY_": "Stop gracefully",
      "_SPARK_CORES_MAX_": "Cores max",
      "_SPARK_EXECUTOR_MEMORY_": "Executor memory",
      "_SPARK_EXECUTOR_CORES_": "Executor cores",
      "_SPARK_DRIVER_MEMORY_": "Driver memory",
      "_SPARK_DRIVER_CORES_": "Driver cores",
      "_SPARK_EXTRA_CORES_": "Extra cores",
      "_SPARK_LOCALITY_WAIT_": "Locality wait",
      "_SPARK_TASK_MAX_FAILURES_": "Task max failures",
      "_SPARK_BLOCK_INTERVAL_": "Block interval",
      "_SPARK_CONCURRENT_JOBS_": "Concurrent jobs",
      "_SPARK_DOCKER_IMAGE_": "Executor docker image",
      "_SPARK_DOCKER_VOLUMES_": "Volumes",
      "_SPARK_STREAMING_BACK_PRESSURE_": "Back pressure",
      "_SPARK_STREAMING_BACK_PRESSURE_INITIAL_RATE_": "Back pressure receivers initial rate",
      "_SPARK_STREAMING_BACK_PRESSURE_MAX_RATE_": "Back pressure receivers max rate",
      "_SPARK_SUBMIT_ARGUMENTS_": "User arguments",
      "_SPARK_SUBMIT_ARGUMENT_KEY_": "Argument key",
      "_SPARK_SUBMIT_ARGUMENT_VALUE_": "Argument value",
      "_SPARK_DEPLOY_MODE_": "Deploy mode",
      "_SPARK_SUPERVISE_": "Supervise",
      "_SPARK_JARS_": "Provided jars",
      "_SPARK_PROPERTIES_FILE_": "Provided properties file",
      "_SPARK_PACKAGES_": "Maven included packages",
      "_SPARK_EXCLUDE_PACKAGES_": "Maven excluded packages",
      "_SPARK_REPOSITORIES_": "Maven repositories",
      "_SPARK_PROXY_USER_": "Proxy user",
      "_SPARK_DRIVER_JAVA_OPTIONS_": "Driver Java options",
      "_SPARK_DRIVER_LIBRARY_PATH_": "Driver libraries",
      "_SPARK_DRIVER_CLASS_PATH_": "Driver class path entries",
      "_SPARK_MEMORY_FRACTION_": "Memory fraction",
      "_SPARK_DOCKER_FORCE_PULL_IMAGE_": "Force pull image",
      "_SPARK_MESOS_NATIVE_LIBRARY_": "Native library",
      "_SPARK_MESOS_HDFS_CONF_URI_": "HDFS configuration uri",
      "_SPARK_CONF_KEY_": "Configuration key",
      "_SPARK_CONF_VALUE_": "Configuration value",
      "_SPARK_LOCAL_DIR_": "Spark local path",
      "_SPARK_EXECUTOR_JAVA_OPTIONS_": "Executor Java options",
      "_WORKFLOW_REMEMBER_FIELD_": "Remember time"
   },
   "_DISCARD_CONDITIONS_": "Discard conditions",
   "_PREVIOUS_FIELD_": "Previous field to compare",
   "_TRANSFORMED_FIELD_": "Transformed field to compare",
   "_ORDER_EXPRESSION_": "Order By expression",
   "_WATER_MARK_": "Water mark",
   "_TIMEOUT_KEY_": "Timeout",
   "_DIMENSIONS_": "Dimensions",
   "_OPERATORS_": "Operators",
   "_CLASS_TYPE_": "Class type",
   "_TIME_DIMENSION_": "Time dimension",
   "_GRANULARITY_": "Granularity",
   "_AVAILABILITY_": "Availability",
   "_TIME_DATA_TYPE_": "Time type",
   "_REMEMBER_PARTITIONER_": "Remember partitioner",
   "_POSTGRES_NEW_QUOTE_SUBSTITUTION_": "Quoting character to be used",
   "_KAFKA_OUTPUT_FORMAT_": "Output format",
   "_INPUT_SCHEMA_FROM_": "Input schema from",
   "_HEADER_": "Header",
   "_HEADER_REMOVAL_": "Remove header from rows",
   "_SPARK_SCHEMA_": "Spark schema",
   "_SPLIT_METHOD_": "Splitting method",
   "_BYREGEX_PATTERN_": "Regex pattern",
   "_BYCHAR_PATTERN_": "Char pattern",
   "_BYINDEX_PATTERN_": "Index pattern",
   "_EXCLUDE_INDEXES_": "Exclude indexes",
   "_REMOVE_INPUT_FIELD_": "Remove input field",
   "_KAFKA_ROW_SEPARATOR_": "Row separator",
   "_DESERIALIZER_JSON_SCHEMA_": "Json/Spark schema",
   "_DESERIALIZER_AVRO_SCHEMA_": "Avro schema",
   "_KAFKA_AVRO_SCHEMA_FROM_ROW_": "Avro schema from each row",
   "_KAFKA_AVRO_SCHEMA_RECORD_NAME": "Avro schema record name",
   "_KAFKA_AVRO_SCHEMA_RECORD_NAMESPACE_": "Avro schema record namespace",
   "_KEY_SEPARATOR_": "Key separator",
   "_VAULT_TLS_ENABLE_": "Vault TLS enable",
   "_DESERIALIZER_INPUT_FORMAT_": "Deserializer input format",
   "_DESERIALIZER_SCHEMA_": "Schema",
   "_INPUT_FIELD_": "Input field",
   "_FIELD_": "Field",
   "_OUTPUT_FIELD_": "Output field",
   "_OUTPUT_TYPE_": "Output type",
   "_ANALYSIS_TYPE_": "Analysis type",
   "_COLUMNS_TO_ANALYZE_": "Columns to analyze",
   "_DATA_ZONE_": "Data zone",
   "_COLUMN_NAME_PROFILING_": "Column name",
   "_NULL_ANALYSIS_": "Execute null analysis",
   "_CHARACTERS_ANALYSIS_": "Execute characters analysis",
   "_EXECUTION_DATE_": "Execution date",
   "_LIMIT_RESULTS_": "Limit results",
   "_EVENT_": "Event",
   "_EVENT_TYPE_": "Event type",
   "_MAX_NUMBER_": "Max number",
   "_EXPLODED_FIELD_": "Exploded field",
   "_MAX_NUMBER_EVENTS_": "Stop generating after (num. of events)",
   "_NUMBER_EVENTS_": "Number of events per windows",
   "_NUMBER_EVENTS_BATCH_": "Number of events",
   "_OUTPUT_FIELDS_FROM_": "Output fields from",
   "_FIELDS_DEFINITION_STRING_": "Fields string definition",
   "_FIELDS_DEFINITION_": "Fields definition",
   "_RESOURCE_": "Resource",
   "_READ_METADATA_": "Read metadata",
   "_PIPELINE_": "Pipeline descriptor",
   "_OUTPUT_MODE_": "Where to save trained Pipeline",
   "_MODELREP_MODEL_NAME_": "Model name used to store built pipeline",
   "_MODELREP_SERIALIZATION_LIB_": "Serialization library used to save the pipeline",
   "_MODELREP_TMP_DIR_":"Temporary directory used to save the trained pipelineModel",
   "_MLPIPELINE_VALIDATE_CONNECTION_": "Validates connection to Ml-Model-repository",
   "_NAME_": "Name",
   "_NULLABLE_": "Nullable",
   "_INTERVAL_": "Interval",
   "_PARTITIONS_": "Partitions",
   "_DEFAULT_COLUMN_VALUES_": "Default column values",
   "_DEFAULT_TYPE_VALUES_": "Default types values",
   "_COLUMN_VALUE_": "Value",
   "_RESET_ON_START_": "Reset offsets on start",
   "_IGNORE_STARTED_STATUS_": "Ignore started status when reset offsets",
   "_FILTER_EXPRESSION_": "Filter expression",
   "_SELECT_EXPRESSION_": "Select expression",
   "_SUPPORT_NULL_VALUES_": "Support null values",
   "_SQL_": "Sql query",
   "_ADD_ALL_INPUT_FIELDS_": "Add all input fields",
   "_TRANSFORMATION_WHEN_ERROR_": "Error handling policy",
   "_TRANSFORMATION_WHEN_ROW_ERROR_": "Row error handling policy",
   "_TRANSFORMATION_WHEN_FIELD_ERROR_": "Field error handling policy",
   "_OVER_LAST_": "Over last",
   "_COMPUTE_EVERY_": "Compute every",
   "_SPLIT_LIMIT_": "Split limit",
   "_DELIMITER_TYPE_": "Delimiter type",
   "_PORT_": "Port",
   "_TCP_PORT_": "TCP Port",
   "_HTTP_PORT_": "HTTP Port",
   "_GROUP_ID_": "Group ID",
   "_KEY_DESERIALIZER_": "Key Deserializer",
   "_VALUE_DESERIALIZER_": "Value Deserializer",
   "_MAX_BATCH_SIZE": "Max batch size",
   "_PARALLELISM_": "Parallelism",
   "_HOST_NAME_": "Host name",
   "_HOST_": "Host",
   "_HOSTS_": "Hosts",
   "_DECOMPRESSION_": "Decompression",
   "_ZOOKEEPER_HOST_": "Zookeeper host",
   "_ZOOKEEPER_PORT_": "Zookeeper port",
   "_PARTITION_STRATEGY_": "Partition Strategy",
   "_LOCATION_STRATEGY_": "Location Strategy",
   "_TOPICS_": "Topics",
   "_TOPIC_": "Topic",
   "_BROKER_": "Broker",
   "_QUEUE_": "Queue",
   "_EXCHANGE_NAME_": "Exchange name",
   "_SPARK_KERBEROS_ENABLE_": "Spark Kerberos",
   "_ROUTING_KEYS_": "Routing keys",
   "_ROUTING_KEY_": "Routing key",
   "_CONSUMER_KEY_": "Consumer key",
   "_CONSUMER_SECRET_": "Consumer secret",
   "_ACCESS_TOKEN_": "Access token",
   "_TOKEN_SECRET_": "Token secret",
   "_TERMS_OF_SEARCH_": "Search terms",
   "_PARTITION_": "Partitions",
   "_CONTACT_POINT_": "Contact point",
   "_KEYSPACE_": "Keyspace",
   "_CLUSTER_": "Cluster name",
   "_KEYSPACE_CLASS_": "keyspace class",
   "_REPLICATION_FACTOR_": "Replication factor",
   "_COMPACT_STORAGE_": "Compact storage",
   "_LUCENE_ANALYZER_": "Lucene Analyzer",
   "_REFRESH_SECONDS_": "Refresh seconds",
   "_DATAFIELD_": "Data Field",
   "_TIMEFIELD_": "Time Field",
   "_DATE_FORMAT_": "Date format",
   "_OUTPUT_NAME_": "Output field name",
   "_DATE_TYPE_": "Output field type",
   "_FORMAT_FROM_": "Format from",
   "_GRANULARITY_NUMBER_": "User-defined granularity",
   "_GRANULARITY_TIME_": "Granularity time unit",
   "_FIELDS_DATETIME_DEFINITION_": "Fields to convert",
   "_USER_FORMAT_": "User format",
   "_STANDARD_FORMAT_": "Standard format",
   "_LOCALE_TIME_": "Locale",
   "_OUTPUT_STANDARD_FORMAT_": "Standard output format",
   "_OUTPUT_FORMAT_FROM_": "Output format",
   "_OUTPUT_USER_FORMAT_": "User-defined output format",
   "_PATH_": "Path",
   "_TABLE_": "Table",
   "_PRIMARY_KEY_": "Primary key",
   "_PARTITION_BY_": "Partition By",
   "_UNIQUE_CONSTRAINT_NAME_" : "Unique Constraint Name",
   "_UNIQUE_CONSTRAINT_FIELDS_" : "Unique Constraint Fields",
   "_CONSTRAINT_TYPE_" : "Constraint type",
   "_TRIGGER_PARTITION_BY_HELP_": "Partition the output by one or more fields, separated by ','. This property is supported by outputs that write on file systems",
   "_INFER_SCHEMA_": "Infer schema",
   "_DELIMITER_": "Delimiter",
   "_ID_FIELD_": "Id field",
   "_INDEX_MAPPING_": "Index mapping",
   "_ENABLE_INDEX_AUTO_CREATE_": "Enable automatic index creation",
   "_DATEBASE_NAME_": "Database name",
   "_CONNECTIONS_PER_HOST_": "Connections per host",
   "_THREADS_ALLOWED_TO_BLOCK_": "Max threads allowed",
   "_STORE_ROW_ID_AS_INDEPENDENT_FIELD_": "Store row ID as independent field",
   "_LANGUAGE_": "Language",
   "_RETRY_SLEEP_": "Retry sleep",
   "_TIME_STAMP_FIELD_NAME_": "Time stamp field name",
   "_KEY_SERIALIZER_": "Key Serializer",
   "_KAFKA_STORE_OFFSET_ITSELF_": "Store offsets in Kafka",
   "_KAFKA_AUTO_OFFSET_": "Auto offset",
   "_KAFKA_ENABLE_AUTOCOMMIT_": "Auto commit",
   "_MAX_POLL_TIMEOUT_": "Spark consumer poll timeout",
   "_CACHED_CONSUMER_": "Cached consumer",
   "_MAX_RATE_PER_PARTITION_": "Max rate per partition",
   "_KAFKA_PROPERTY_KEY_": "Kafka property",
   "_TIME_STAMP_MAPPING_": "Timestamp data format",
   "_KAFKA_PROPERTY_VALUE_": "Value",
   "_BOOTSTRAP_SERVERS_": "Bootstrap servers list",
   "_TLS_ENABLE_": "TLS enabled",
   "_OUTPUT_FORMAT_": "Output format",
   "_LIMIT_RECORDS_": "Limit records",
   "_KAFKA_PROPERTIES_": "Kafka properties",
   "_STORAGELEVEL_": "Storage level",
   "_SHUFFLE_": "Shuffle",
   "_RABBITMQ_PROPERTY_KEY_": "RabbitMQ property",
   "_RABBITMQ_PROPERTY_VALUE_": "Value",
   "_RABBITMQ_RECEIVER_TYPE_": "RabbitMQ receiver type",
   "_RABBITMQ_PROPERTIES_": "RabbitMQ properties",
   "_RABBITMQ_DISTRIBUTED_PROPERTIES_": "RabbitMQ Distributed properties",
   "_RABBITMQ_QUEUE_KEY_": "Queue",
   "_RABBITMQ_EXCHANGE_NAME_KEY_": "Exchange",
   "_RABBITMQ_EXCHANGE_TYPE_KEY_": "Exchange type",
   "_RABBITMQ_ROUTING_KEYS_KEY_": "Routing keys",
   "_QUERY_": "Query",
   "_QUERIES_": "Queries",
   "_TYPE_": "Type",
   "_MODEL_": "Model",
   "_MODEL_TYPE_": "Model type",
   "_URL_": "URL",
   "_DIRECTORY_": "Directory",
   "_ADDRESSES_": "Addresses",
   "_OFFSET_FILED_": "Offset field",
   "_OFFSET_OPERATOR_": "Offset operator",
   "_OFFSET_VALUE_": "Offset value",
   "_OFFSET_LOCATION_": "Offset location",
   "_OFFSET_FIELDS_": "Fields defining offset condition",
   "_ZOOKEEPER_CONNECTION_": "Zookeeper connection",
   "_REMEMBER_DURATION_": "Remember duration",
   "_FROM_BEGINNING_": "From beginning",
   "_STOP_CONTEXTS_WHEN_EMPTY_": "Stop contexts when empty",
   "_FINISH_APP_WHEN_EMPTY_": "Stop application when empty",
   "_FORCED_BEGINNING_": "Forced beginning",
   "_ZOOKEEPER_PATH_": "Zookeeper path",
   "_INITIAL_SENTENCE_": "Initial sentence",
   "_STOP_GRACEFULLY_": "Stop Gracefully",
   "_CA_NAME_": "CA Name",
   "_SCHEMA_FROM_DATABASE_": "Extract schema from database",
   "_OPTION_PROPERTIES_": "Option properties",
   "_OPTION_KEY_": "Option key",
   "_OPTION_VALUE_": "Option value",
   "TEMPLATE_NAME": "Name",
   "TEMPLATE_DESCRIPTION": "Description",
   "_POSTGRES_SAVE_PROPERTIES_": "Postgres save properties",
   "_POSTGRES_BUFFER_SIZE_": "Buffer size",
   "_POSTGRES_DELIMITER_": "Delimiter character",
   "_POSTGRES_NEW_LINE_SUBSTITUTION_": "Character to new line substitution",
   "_POSTGRES_SAVE_MODE_": "Postgres save mode",
   "_DROP_TEMP_TABLE_SUCCESS_" : "Drop temporary table on success",
   "_DROP_TEMP_TABLE_FAILURE_" : "Drop temporary table on failure",
   "_JDBC_SAVE_MODE_": "Jdbc save mode",
   "_POSTGRES_ENCODING_": "Encoding",
   "_JDBC_URL_": "url",
   "_JDBC_SAVE_PROPERTIES_": "JDBC save properties",
   "_JDBC_DRIVER_": "Driver",
   "_JDBC_BATCH_SIZE_": "Batch size",
   "_ISOLATION_LEVEL_": "Isolation Level",
   "_SAVE_OPTIONS_KEY_": "Property",
   "_SAVE_OPTIONS_VALUE_": "Value",
   "_SPARK_PROPERTIES_": "Spark properties",
   "_SPARK_CONF_": "User configuration properties",
   "_CASSANDRA_SAVE_PROPERTIES_": "Cassandra save properties",
   "_CLEAN_MODE_": "Clean mode",
   "_SPARK_PROPERTY_KEY_": "Spark property",
   "_SPARK_PROPERTY_VALUE_": "Value",
   "_NODES_": "Nodes",
   "_CLUSTER_NAME_": "Cluster name",
   "_ELASTICSEARCH_SAVE_PROPERTIES_": "ElasticSearch save properties",
   "_PARQUET_SAVE_PROPERTIES_": "Parquet save properties",
   "_MONGODB_SAVE_PROPERTIES_": "MongoDB save properties",
   "_CSV_SAVE_PROPERTIES_": "CSV save properties",
   "_AVRO_SAVE_PROPERTIES_": "Avro save properties",
   "_JSON_SAVE_PROPERTIES_": "Json save properties",
   "_TEXT_SAVE_PROPERTIES_": "Text save properties",
   "_VALUE_SERIALIZER_": "Value Serializer",
   "_COLUMNS_": "Columns",
   "_COLUMN_NAME_": "Name",
   "_JOIN_LEFT_TABLE_": "Left table",
   "_JOIN_RIGHT_TABLE_": "Right table",
   "_JOIN_TYPE_": "Join type",
   "_JOIN_RETURN_": "Fields to return",
   "_JOIN_CONDITIONS_": "Join conditions",
   "_JOIN_CONDITION_LEFT_": "Left table field",
   "_JOIN_CONDITION_RIGHT_": "Right table field",
   "_JOIN_RETURN_COLUMNS_": "Select columns to return",
   "_JOIN_RETURN_SIDE_": "Table side",
   "_JOIN_RETURN_COLUMN_": "Column name",
   "_JOIN_RETURN_ALIAS_": "Alias",
   "_ACKS_": "Acks",
   "_KAFKA_FORMAT_": "Format",
   "_SELECT_TYPE_": "Input mode",
   "_SELECT_COLUMNS_": "Columns",
   "_BATCH_NUM_MESSAGES_": "Batch num messages",
   "_SECURITY_PROTOCOL_": "Security Protocol",
   "_POST_TYPE_": "Post type",
   "_PARAMETER_NAME_": "Parameter name",
   "_CONN_TIMEOUT_": "Connection timeout",
   "_READ_TIMEOUT_": "Read timeout",
   "_LOG_LEVEL_": "Log level",
   "_PRINT_SCHEMA_": "Print Schema",
   "_PRINT_META_DATA_": "Print metadata",
   "_PRINT_DATA_": "Print data",
   "_SSL_TRUSTSTORE_LOCATION_": "SSL Truststore Location",
   "_SSL_TRUSTSTORE_PASSWORD_": "SSL Truststore Password",
   "_SSL_KEYSTORE_LOCATION_": "SSL KeyStore Location",
   "_SSL_KEYSTORE_PASSWORD_": "SSL KeyStore Password",
   "_SSL_KEY_PASSWORD_": "SSL Key Password",
   "_SECURITY_AUTH_": "Security Client Auth",
   "_SAVEMODE_": "Save mode",
   "_TABLE_NAME_": "Table name",
   "_ERROR_TABLE_NAME_": "Errors table name",
   "_ERROR_SINK_": "Available in errors management",
   "_NEW_FILES_ONLY_": "New files only",
   "_FILTER_OUT_FILES_": "Filter",
   "_SCHEMA_FROM_ROW_": "Infer schema for each row",
   "_SCHEMA_": "Schema",
   "_EXAMPLE_": "Example",
   "_FIELDS_PRESERVATION_": "Build output row by",
   "_KEY_": "Name",
   "_VALUE_": "Value",
   "_INPUTS_TRIGGER_SCHEMA_": "Provided input schemas",
   "_EXECUTE_WHEN_EMPTY_": "Execute query when is not possible to obtain schema",
   "_INPUT_STEP_NAME_" : "Step name",
   "_COLUMNS_TO_DROP_" : "Columns to delete",
   "_COLUMNS_TO_RENAME_" : "Columns to Rename",
   "_NEW_COLUMN_NAME_": "New column name",
   "_COLUMNS_TO_ADD_" : "Columns to add",
   "_FAIL_FAST_" : "Fail Fast",
   "_ROWTAG_" : "The XML file row tag to be treated as a row",
   "_ROOT_TAG_" : "The XML file root tag to be treated as the root",
   "_XML_MODE_": "Policy for dealing with corrupt records",
   "_XML_SAVE_PROPERTIES_": "XML save properties",
   "_DATASOURCE_FORMAT_": "Spark SQL datasource",
   "_DATASOURCE_SAVE_PROPERTIES_": "Datasource save properties",
   "_DATASOURCE_TABLE_KEY_": "Table option key",
   "_DATASOURCE_TABLE_PATTERN_": "Table option value (pattern)",
   "_HTTPS_PROPERTIES_": "HTTPS options",
   "_HTTPS_PROPERTY_KEY_": "HTTPS name",
   "_HTTPS_PROPERTY_VALUE_": "HTTPS value",
   "_AKKA_HTTP_PROPERTIES_": "Akka-HTTP options",
   "_AKKA_HTTP_PROPERTY_KEY_": "Akka-HTTP name",
   "_AKKA_HTTP_PROPERTY_VALUE_": "Akka-HTTP value",
   "_USE_HTTPS_": "Use HTTPS",
   "_HTTP_OUTPUT_FIELD_": "Output field name",
   "_HTTP_BODY_": "HTTP Body",
   "_HTTP_BODY_FORMAT_": "Body Format",
   "_HTTP_HEADER_": "HTTP Header",
   "_HTTP_METHOD_": "HTTP Method",
   "_HEADER_PROPERTY_KEY_": "Header property name",
   "_HEADER_PROPERTY_VALUE_": "Header property value",
   "_HTTP_STATUS_CODE_WHITELIST_" : "Comma-separated values of allowed status codes",
   "_REQUEST_TIMEOUT_": "Request timeout",
   "FORM_TABS": {
      "STREAMINGSETTINGS": "Streaming",
      "SPARKSETTINGS": "Spark",
      "ERRORSMANAGEMENT": "Errors Management",
      "GLOBAL": "Global"
   },
   "PLUGINS": {
      "NO_ITEMS": "There are no plugins created yet.",
      "NO_ITEMS_LINK": "Upload one"
   },
   "BACKUPS": {
      "NO_ITEMS": "There are no backups created yet.",
      "NO_ITEMS_LINK": "Create one"
   },
   "TEMPLATES": {
      "NO_ITEMS_LINK": "Add one",
      "INPUTS": {
         "NO_ITEMS": "There are no input templates created yet."
      },
      "OUTPUTS": {
         "NO_ITEMS": "There are no output templates created yet."
      },
      "TRANSFORMATIONS": {
         "NO_ITEMS": "There are no transformation templates created yet."
      }
   },
   "ALERTS": {
      "SUCCESS": "Success",
      "ERROR": "Error",
      "WARNING": "Warning",
      "EXPIRED_SESSION": "The session has been expired",
      "EXECUTE_BACKUP_DESCRIPTION": "Backup executed correctly",
      "UPLOAD_BACKUP_DESCRIPTION": "Backup uploaded correctly",
      "GENERATE_BACKUP_DESCRIPTION": "Backup generated correctly",
      "DELETE_BACKUP_DESCRIPTION": "The backup has been deleted",
      "DELETE_METADATA_DESCRIPTION": "Metadata has been deleted",
      "CREATED_WORKFLOW": "Workflow has been created succesfully",
      "RUN_WORKFLOW": "The workflow {{name}} is running!",
      "STOP_WORKFLOW": "The workflow is stopping!",
      "DELETE_WORKFLOW": "Workflow/s have been deleted.",
      "DELETE_VERSION": "Version/s have been deleted.",
      "DELETE_GROUP": "Group/s have been deleted",
      "GENERATE_NEW_VERSION": "The version of the workflow has been generated succesfully",
      "LIST_INPUT_ERROR": "Cannot get input template list",
      "LIST_OUTPUT_ERROR": "Cannot get outputs template list",
      "LIST_TRANSFORMATION_ERROR": "Cannot get transformations template list",
      "LIST_WORKFLOW_ERROR": "Cannot get workflow list",
      "MENU_TEMPLATES_ERROR": "Cannot get templates",
      "UPDATE_INPUT_DESCRIPTION": "Input has been saved",
      "UPDATE_OUTPUT_DESCRIPTION": "Output has been saved",
      "UPDATE_TRANSFORMATION_DESCRIPTION": "Transformation has been saved",
      "CREATE_INPUT_DESCRIPTION": "Input has been created succesfully",
      "CREATE_OUTPUT_DESCRIPTION": "Output has been created succesfully",
      "CREATE_TRANSFORMATION_DESCRIPTION": "Transformation has been created succesfully",
      "NO_ENTITY_WORKFLOW_TITLE": "Validation error",
      "NO_ENTITY_WORKFLOW_MESSAGE": "Workflow must have at least one node",
      "VALIDATION_ERRORS_MESSAGE": "At least one node has errors",
      "VALIDATION_ERRORS_TITLE": "Validation error",
      "WORKFLOW_SERVER_ERROR_TITLE": "Server error",
      "WORKFLOW_SERVER_ERROR_DESCRIPTION": "Workflow cannot be saved",
      "SERVER_ERROR": "Server error",
      "SAVE_ENVIRONMENT": "The environment variables have been saved",
      "EXPORT_ENVIRONMENT": "The environment data have been exported",
      "IMPORT_ENVIRONMENT": "The environment data have been imported",
      "INVALID_ENVIRONMENT_FILE": "The selected environment file format is invalid",
      "DELETE_INPUT_DESCRIPTION": "The input/s has been deleted",
      "DELETE_OUTPUT_DESCRIPTION": "The output/s has been deleted",
      "DELETE_TRANSFORMATION_DESCRIPTION": "The transformation/s has been deleted",
      "DUPLICATED_WORKFLOW": "Workflow has been duplicated succesfully"
   },
   "WIZARD": {
      "INPUTS": "Inputs",
      "OUTPUTS": "Outputs",
      "TRANSFORMATIONS": "Transformations",
      "CANCEL": "Cancel",
      "SAVE": "Save",
      "DONT_SAVE": "Do not save",
      "SAVE_EXIT": "Save and exit",
      "NOT_SAVE_EXIT": "Don't save and Exit",
      "RETURN_WORKFLOW": "Return to workflow list",
      "CONFIRM_EXIT": "Save changes to the workflow?",
      "LOSE_CHANGES_EXIT": "If you leave this page without saving, your changes will be lost and it will not be possible to recover them.",
      "DELETE_WORKFLOW_MESSAGE": "Are you sure?",
      "CONFIRM_EXIT_ADVICE": "If you donÂ´t save the changes, they will be lost.",
      "SUBMITARGUMENTS": "Submit Arguments",
      "SPARKCONF": "Spark Configuration",
      "SPARKRESOURCESCONF": "Resources",
      "SPARKDOCKERCONF": "Docker",
      "SPARKMESOSCONF": "Mesos",
      "CHECKPOINTSETTINGS": "Checkpoint",
      "INPUTSTEPSMANAGEMENT": "Input Steps",
      "GENERICERRORMANAGEMENT": "Application-wide policy",
      "TRANSFORMATIONSTEPSMANAGEMENT": "Transformation-wide policy",
      "TRANSACTIONSMANAGEMENT": "Error sinks",
      "SAVEACTIONMANAGEMENT": "Save Steps",
      "SETTINGS": "Workflow Settings",
      "DEBUG_ERROR_DETAILS": "Debug error details",
      "DEBUG_ERROR_DATE": "Date",
      "DEBUG_ERROR_PHASE": "Phase",
      "MENU_SEARCH": "Search...",
      "VALIDATION_ERROR_1": "There is a validation error:",
      "VALIDATION_ERROR_N": "Validation errors:",
      "NO_VALIDATION_ERROR": "No validation errors.",
      "NODE_NAME_VALIDATION": "There is another node with the same name",
      "STEP_VALIDATIONS": "There are validation errors in one or more steps",
      "OUTPUT_STEPS": "Output steps",
      "INPUT_STEPS": "Input steps",
      "VIEW_DEBUG_DATA": "View debug data",
      "DEBUG_DATA_FLOWING": "Data succesfully flowing",
      "VIEW_ERROR_DETAILS": "View details",
      "GENERIC_ERROR": "Oops!. Data not flowing correctly. There are one or more generic errors",
      "QUERY_BUILDER": {
        "NO_INPUT_SCHEMAS": "You must either add at least one input or run a debug execution to use this query builder."
      },
      "RELATIONS": {
        "DEFAULT": "Default relation",
        "VALIDDATA": "Valid data",
        "DISCARDEDDATA": "Discarded data"
      },
      "MOCKS": {
        "PASTE": "Paste",
        "PASTE_PLACEHOLDER": "Paste your input data here",
        "UPLOAD": "Upload a file",
        "UPLOAD_FILE_BUTTON": "Paste text from file",
        "URI": "From URI",
        "URI_PLACEHOLDER": "Paste the URI",
        "SQL": "Query SQL"
      },
      "NOTIFICATION": {
        "WORKFLOW_SAVE_SUCCESS": "Workflow has been saved succesfully",
        "DEBUG_SUCCESS": "Execution in debug mode has been successful",
        "DEBUG_FAIL": "The execution in debug mode has errors",
        "DEBUG_GENERIC_FAIL": "There has been a generic error when executing the debug",
        "DEBUG_RUN": "Workflow debug mode is running"
      }
   },
   "ERRORS": {
      "401": "You do not have permissions to perform this action",
      "404": "404: Page missing",
      "INPUTS": {
         "GENERIC": "Error",
         "REQUIRED": "This field is required",
         "MINLENGTH": "The field min length is",
         "MAXLENGTH": "The field max length is",
         "MIN": "The number has to be higher than: ",
         "MAX": "The number has to be minor than: ",
         "PATTERN": "The value is invalid"
      }
   },
   "EXECUTIONS": {
      "EMPTY_TITLE": "There are no Executions created yet",
      "EMPTY_TEXT": "Executions can be launched from the repository. Try to select a version of a workflow and run it.",
      "EMPTY_LINK": "Go to Repository"
   }
}
