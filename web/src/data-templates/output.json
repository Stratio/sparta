[
  {
    "name": "Cassandra",
    "modelType": "Cassandra",
    "description": {
      "short": "The Cassandra output uses the generic implementation with DataFrames.",
      "long": "The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-Cassandra"
    },
    "properties": [
      {
        "propertyId": "connectionHost",
        "propertyName": "_CONTACT_POINT_",
        "propertyType": "text",
        "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
        "default": "localhost",
        "required": true,
        "tooltip": "",
        "qa": "fragment-details-cassandra-connectionHost"
      },
      {
        "propertyId": "connectionPort",
        "propertyName": "_PORT_",
        "propertyType": "text",
        "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
        "default": "9042",
        "required": true,
        "tooltip": "Cassandra port",
        "hidden": false,
        "qa": "fragment-details-cassandra-connectionPort"
      },
      {
        "propertyId": "keyspace",
        "propertyName": "_KEYSPACE_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": true,
        "tooltip": "Keyspace name.",
        "qa": "fragment-details-cassandra-keyspace"
      },
      {
        "propertyId": "cluster",
        "propertyName": "_CLUSTER_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": true,
        "tooltip": "Cluster name.",
        "qa": "fragment-details-cassandra-cluster"
      },
      {
        "propertyId": "keyspaceClass",
        "propertyName": "_KEYSPACE_CLASS_",
        "propertyType": "select",
        "regexp": "simpleStrategy|networkTopologyStrategy",
        "values": [
          {
            "label": "SimpleStrategy",
            "value": "simpleStrategy"
          },
          {
            "label": "NetworkTopologyStrategy",
            "value": "networkTopologyStrategy"
          }
        ],
        "default": "simpleStrategy",
        "required": true,
        "tooltip": "KeySpace class.",
        "qa": "fragment-details-cassandra-keyspaceClass"
      },
      {
        "propertyId": "replication_factor",
        "propertyName": "_REPLICATION_FACTOR_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "1",
        "required": true,
        "tooltip": "Specifies the number of replicas of data on multiple nodes.",
        "qa": "fragment-details-cassandra-replication-factor"
      },
      {
        "propertyId": "compactStorage",
        "propertyName": "_COMPACT_STORAGE_",
        "propertyType": "boolean",
        "regexp": "true|false",
        "default": false,
        "required": false,
        "tooltip": "The compact storage directive is used for backward compatibility of CQL 2 applications and data in the legacy (Thrift) storage engine format. To take advantage of CQL 3 capabilities, do not use this directive in new applications. When you create a table using compound primary keys, for every piece of data stored, he column name needs to be stored along with it. Instead of each non-primary key column being stored such that each column corresponds to one column on disk, an entire row is stored in a single column on disk, hence the name compact storage.",
        "qa": "fragment-details-cassandra-compactStorage"
      },
      {
        "propertyId": "analyzer",
        "propertyName": "_LUCENE_ANALYZER_",
        "propertyType": "text",
        "regexp": "",
        "default": "english",
        "required": false,
        "tooltip": "The analyzer for text index fields, this feature is for the Stratio’s Cassandra Lucene Index",
        "qa": "fragment-details-cassandra-analyzer"
      },
      {
        "propertyId": "refreshSeconds",
        "propertyName": "_REFRESH_SECONDS_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "1",
        "required": false,
        "tooltip": "The number of seconds between refresh lucene index operations, this feature is for the Stratio’s Cassandra Lucene Index",
        "qa": "fragment-details-cassandra-refreshSeconds"
      },
      {
        "propertyId": "dateFormat",
        "propertyName": "_DATE_FORMAT_",
        "propertyType": "select",
        "regexp": "",
        "values": [
          {
            "label": "yyyy-mm-dd HH:mm",
            "value": "yyyy-mm-dd HH:mm"
          },
          {
            "label": "yyyy-mm-dd HH:mm:ss",
            "value": "yyyy-mm-dd HH:mm:ss"
          },
          {
            "label": "yyyy-mm-dd HH:mmZ",
            "value": "yyyy-mm-dd HH:mmZ"
          },
          {
            "label": "yyyy-mm-dd HH:mm:ssZ",
            "value": "yyyy-mm-dd HH:mm:ssZ"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mm",
            "value": "yyyy-mm-dd'T'HH:mm"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mmZ",
            "value": "yyyy-mm-dd'T'HH:mmZ"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mm:ss",
            "value": "yyyy-mm-dd'T'HH:mm:ss"
          },
          {
            "label": "yyyy-mm-dd'T'HH:mm:ssZ",
            "value": "yyyy-mm-dd'T'HH:mm:ssZ"
          },
          {
            "label": "yyyy-mm-dd",
            "value": "yyyy-mm-dd"
          },
          {
            "label": "yyyy-mm-ddZ",
            "value": "yyyy-mm-ddZ"
          }
        ],
        "default": "yyyy-mm-dd HH:mm",
        "required": false,
        "tooltip": "The date format for the date fields indexed, this feature is for the Stratio’s Cassandra Lucene Index",
        "qa": "fragment-details-cassandra-dateFormat"
      },
      {
        "propertyId": "sparkProperties",
        "propertyName": "_SPARK_PROPERTIES_",
        "propertyType": "list",
        "default": "",
        "required": false,
        "tooltip": "",
        "qa": "fragment-details-cassandra-spark",
        "fields": [
          {
            "propertyId": "sparkPropertyKey",
            "propertyName": "_SPARK_PROPERTY_KEY_",
            "propertyType": "text",
            "regexp": "",
            "default": "spark.cassandra.connection.keep_alive_ms",
            "hidden": false,
            "required": false,
            "qa": "fragment-details-cassandra-sparkPropertyKey"
          },
          {
            "propertyId": "sparkPropertyValue",
            "propertyName": "_SPARK_PROPERTY_VALUE_",
            "propertyType": "text",
            "regexp": "",
            "default": "180000",
            "hidden": false,
            "required": true,
            "qa": "fragment-details-cassandra-sparkPropertyValue"
          }
        ]
      }
    ]
  },
  {
    "name": "CSV",
    "modelType": "Csv",
    "description": {
      "short": "Persist your data in HDFS with CSV format.",
      "long": "Persist your data in HDFS with CSV format.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-CSV"
    },
    "properties": [
      {
        "propertyId": "path",
        "propertyName": "_PATH_",
        "propertyType": "text",
        "regexp": "^[a-zA-Z0-9:_\\.\\-\\+/\\\\]{2,}\\.csv$",
        "default": "path_to_csv.csv",
        "required": true,
        "qa": "fragment-details-csv-path"
      },
      {
        "propertyId": "header",
        "propertyName": "_HEADER_",
        "propertyType": "boolean",
        "regexp": "true|false",
        "default": false,
        "required": false,
        "qa": "fragment-details-csv-header"
      },
      {
        "propertyId": "inferSchema",
        "propertyName": "_INFER_SCHEMA_",
        "propertyType": "boolean",
        "regexp": "true|false",
        "default": false,
        "required": false,
        "qa": "fragment-details-csv-inferSchema"
      },
      {
        "propertyId": "delimiter",
        "propertyName": "_DELIMITER_",
        "propertyType": "text",
        "tooltip": "Any character is accepted except: \\ \" #",
        "regexp": "[^\"#\\\\]",
        "maxlength": "1",
        "default": ",",
        "trim": false,
        "required": false,
        "qa": "fragment-details-csv-delimiter"
      }
    ]
  },
  {
    "name": "Elasticsearch",
    "modelType": "ElasticSearch",
    "description": {
      "short": "The Elasticsearch output uses the generic implementation with DataFrames.",
      "long": "Elasticsearch is a search server based on Lucene. It provides a distributed, multitenant-capable full-text search engine with a RESTful web interface and schema-free JSON documents.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-Elasticsearch"
    },
    "properties": [
      {
        "propertyId": "nodes",
        "propertyName": "_NODES_",
        "propertyType": "list",
        "default": "",
        "required": true,
        "hidden": false,
        "limit": 0,
        "tooltip": "",
        "qa": "fragment-details-elasticSearch-nodes",
        "fields": [
          {
            "propertyId": "node",
            "propertyName": "_HOST_",
            "propertyType": "text",
            "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
            "default": "localhost",
            "required": true,
            "qa": "fragment-details-elasticSearch-node"
          },
          {
            "propertyId": "tcpPort",
            "propertyName": "_TCP_PORT_",
            "propertyType": "text",
            "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
            "default": "9300",
            "required": true,
            "qa": "fragment-details-elasticSearch-tcpPort"
          },
          {
            "propertyId": "httpPort",
            "propertyName": "_HTTP_PORT_",
            "propertyType": "text",
            "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
            "default": "9200",
            "required": true,
            "qa": "fragment-details-elasticSearch-httpPort"
          }
        ]
      },
      {
        "propertyId": "clusterName",
        "propertyName": "_CLUSTERNAME_",
        "propertyType": "text",
        "regexp": "",
        "default": "elasticsearch",
        "required": true,
        "qa": "fragment-details-elasticSearch-clusterName"
      },
      {
        "propertyId": "idField",
        "propertyName": "_ID_FIELD_",
        "propertyType": "text",
        "regexp": "",
        "default": "",
        "required": false,
        "qa": "fragment-details-elasticSearch-idField"
      },
      {
        "propertyId": "indexMapping",
        "propertyName": "_INDEX_MAPPING_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": false,
        "qa": "fragment-details-elasticSearch-indexMapping"
      }
    ]
  },
  {
    "name": "MongoDb",
    "modelType": "MongoDb",
    "description": {
      "short": "MongoDB is an open-source document database, and the leading NoSQL database.",
      "long": "MongoDB is an open-source document database that provides high performance, high availability, and automatic scaling.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-MongoDB"
    },
    "properties": [
      {
        "propertyId": "hosts",
        "propertyName": "_HOSTS_",
        "propertyType": "list",
        "default": "",
        "required": true,
        "tooltip": "This parameter connection routes specified the nodes of a cluster of MongoDB, with different replica set or with sharding.",
        "qa": "fragment-details-mongoDb-hosts",
        "fields": [
          {
            "propertyId": "host",
            "propertyName": "_HOST_",
            "propertyType": "text",
            "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
            "default": "localhost",
            "hidden": false,
            "required": true,
            "qa": "fragment-details-mongoDb-hostName"
          },
          {
            "propertyId": "port",
            "propertyName": "_PORT_",
            "propertyType": "text",
            "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
            "default": "27017",
            "hidden": false,
            "required": true,
            "qa": "fragment-details-mongoDb-port"
          }
        ]
      },
      {
        "propertyId": "dbName",
        "propertyName": "_DATEBASE_NAME_",
        "propertyType": "text",
        "regexp": "",
        "default": "sparta",
        "required": true,
        "tooltip": "Name of the database.",
        "qa": "fragment-details-mongoDb-dbName"
      },
      {
        "propertyId": "connectionsPerHost",
        "propertyName": "_CONNECTIONS_PER_HOST_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "5",
        "required": false,
        "tooltip": "Number of connections per host",
        "qa": "fragment-details-mongoDb-connectionsPerHost"
      },
      {
        "propertyId": "threadsAllowedToBlock",
        "propertyName": "_THREADS_ALLOWED_TO_BLOCK_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "10",
        "required": false,
        "tooltip": "This multiplier, multiplied with the connectionsPerHost setting, gives the maximum number of threads that may be waiting for a connection to become available from the pool.",
        "qa": "fragment-details-mongoDb-threadsAllowedToBlock"
      },
      {
        "propertyId": "language",
        "propertyName": "_LANGUAGE_",
        "propertyType": "select",
        "regexp": "",
        "values": [
          {
            "label": "danish",
            "value": "danish"
          },
          {
            "label": "dutch",
            "value": "dutch"
          },
          {
            "label": "english",
            "value": "english"
          },
          {
            "label": "finnish",
            "value": "finnish"
          },
          {
            "label": "french",
            "value": "french"
          },
          {
            "label": "german",
            "value": "german"
          },
          {
            "label": "hungarian",
            "value": "hungarian"
          },
          {
            "label": "italian",
            "value": "italian"
          },
          {
            "label": "norwegian",
            "value": "norwegian"
          },
          {
            "label": "portuguese",
            "value": "portuguese"
          },
          {
            "label": "romanian",
            "value": "romanian"
          },
          {
            "label": "russian",
            "value": "russian"
          },
          {
            "label": "spanish",
            "value": "spanish"
          },
          {
            "label": "swedish",
            "value": "swedish"
          },
          {
            "label": "turkish",
            "value": "turkish"
          }
        ],
        "default": "",
        "required": false,
        "tooltip": "Specify the language of the tokenizer in the full-text index in MongoDB, each document inserted must have this key-value.",
        "qa": "fragment-details-mongoDb-language"
      },
      {
        "propertyId": "retrySleep",
        "propertyName": "_RETRY_SLEEP_",
        "propertyType": "text",
        "regexp": "\\d*",
        "default": "1000",
        "required": false,
        "tooltip": "The number of milliseconds to wait for reconnect with MongoDb nodes when the last client fails. It is recommendable to set less time to the slide interval of the streaming window.",
        "qa": "fragment-details-mongoDb-retrySleep"
      }
    ]
  },
  {
    "name": "Parquet",
    "modelType": "Parquet",
    "description": {
      "short": "Parquet output uses the generic implementation with DataFrames.",
      "long": "Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-Parquet"
    },
    "properties": [
      {
        "propertyId": "path",
        "propertyName": "_PATH_",
        "propertyType": "text",
        "regexp": "",
        "default": "",
        "required": true,
        "tooltip": "",
        "qa": "fragment-details-parquet-path"
      }
    ]
  },
  {
    "name": "Print",
    "modelType": "Print",
    "description": {
      "short": "Print output uses the generic implementation with DataFrames, this implementation print each dataframe with his schema.",
      "long": "Print output uses the generic implementation with DataFrames, this implementation print each dataframe with his schema.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-Print"
    },
    "properties": [
    ]
  },
  {
    "name": "Redis",
    "modelType": "Redis",
    "description": {
      "short": "The output of Redis use the generic implementation with DataFrames.",
      "long": "The output of Redis use the generic implementation with DataFrames. Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker.",
      "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-Redis"
    },
    "properties": [
      {
        "propertyId": "hostname",
        "propertyName": "_HOST_",
        "propertyType": "text",
        "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
        "default": "localhost",
        "required": true,
        "tooltip": "Hostname of the server",
        "qa": "fragment-details-redis-hostname"
      },
      {
        "propertyId": "port",
        "propertyName": "_PORT_",
        "propertyType": "text",
        "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
        "default": "6379",
        "required": true,
        "tooltip": "Port of the server",
        "qa": "fragment-details-redis-port"
      }
    ]
  },
  {
  "name": "Kafka",
  "modelType": "Kafka",
  "description": {
    "short": "Apache Kafka is publish-subscribe messaging rethought as a distributed commit log.",
    "long": "Apache Kafka is publish-subscribe messaging rethought as a distributed commit log. Based on the received-based approach (https://spark.apache.org/docs/latest/streaming-kafka-integration.html)",
    "learnMore": "https://stratio.atlassian.net/wiki/display/SPARTA0x9/Outputs#Outputs-Kafka"
  },
  "properties": [
    {
      "propertyId": "metadata.broker.list",
      "propertyName": "_METADATA_BROKER_LIST_",
      "propertyType": "list",
      "regexp": "",
      "default": "",
      "required": true,
      "tooltip": "Kafka host/port to connect",
      "qa": "fragment-details-kafka-metadata-broker-list",
      "fields": [
        {
          "propertyId": "host",
          "propertyName": "_HOST_",
          "propertyType": "text",
          "regexp": "((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))|(((?![0-9]+$)(?!.*-$)(?!-)[a-zA-Z0-9-]{2,63}))",
          "default": "localhost",
          "required": true,
          "tooltip": "Kafka's address.",
          "hidden": false,
          "qa": "fragment-details-kafka-host"
        },
        {
          "propertyId": "port",
          "propertyName": "_PORT_",
          "propertyType": "text",
          "regexp": "(0|([1-9]\\d{0,3}|[1-5]\\d{4}|[6][0-5][0-5]([0-2]\\d|[3][0-5])))",
          "default": "9092",
          "required": true,
          "tooltip": "Kafka's port.",
          "hidden": false,
          "qa": "fragment-details-kafka-port"
        }
      ]
    },
    {
      "propertyId": "serializer.class",
      "propertyName": "_SERIALIZER_",
      "propertyType": "text",
      "regexp": "",
      "default": "kafka.serializer.StringEncoder",
      "required": true,
      "tooltip": "The serializer class for messages",
      "qa": "fragment-details-kafka-serializer-class"
    },
    {
      "propertyId": "request.required.acks",
      "propertyName": "_REQUIRED_ACKS_",
      "propertyType": "boolean",
      "regexp": "true|false",
      "default": false,
      "required": false,
      "tooltip": "Specify whether producer waits for an acknowledgment from the broker, or not",
      "qa": "fragment-details-kafka-request-required-acks"
    },
    {
      "propertyId": "producer.type",
      "propertyName": "_PRODUCER_TYPE_",
      "propertyType": "text",
      "regexp": "async|sync",
      "default": "async",
      "required": true,
      "tooltip": "This parameter specifies whether the messages are sent asynchronously in a background thread",
      "qa": "fragment-details-kafka-producer-type"
    },
    {
      "propertyId": "batch.num.messages",
      "propertyName": "_BATCH_NUM_MESSAGES_",
      "propertyType": "text",
      "regexp": "[0-9]+",
      "default": "200",
      "required": true,
      "tooltip": "The number of messages to send in one batch when using async mode",
      "qa": "fragment-details-kafka-batch-num-messages"
    },
    {
      "propertyId": "kafkaProperties",
      "propertyName": "_KAFKA_PROPERTIES_",
      "propertyType": "list",
      "default": "",
      "required": false,
      "tooltip": "",
      "qa": "fragment-details-kafka-properties",
      "fields": [
        {
          "propertyId": "kafkaPropertyKey",
          "propertyName": "_KAFKA_PROPERTY_KEY_",
          "propertyType": "text",
          "regexp": "",
          "default": "",
          "hidden": false,
          "required": false,
          "qa": "fragment-details-kafka-kafkaPropertyKey"
        },
        {
          "propertyId": "kafkaPropertyValue",
          "propertyName": "_KAFKA_PROPERTY_VALUE_",
          "propertyType": "text",
          "regexp": "",
          "default": "",
          "hidden": false,
          "required": false,
          "qa": "fragment-details-kafka-kafkaPropertyValue"
        }
      ]
    }
  ]
  },
  {
    "name": "Jdbc",
    "modelType": "Jdbc",
    "description": {
      "short": "With one jdbc connection is possible to write data into SQL Databases.",
      "long": "With one jdbc connection is possible to write data into SQL Databases. Using the generic implementation provided by Spark Datasources Api.",
      "learnMore": "http://spark.apache.org/docs/latest/sql-programming-guide.html#data-sources"
    },
    "properties": [
      {
        "propertyId": "url",
        "propertyName": "_JDBC_URL_",
        "propertyType": "text",
        "regexp": "",
        "default": "jdbc:postgresql:dbserver",
        "required": true,
        "tooltip": "Url to connect to one relational Database with jdbc",
        "qa": "fragment-details-jdbc-url"
      }
    ]
  }
]
